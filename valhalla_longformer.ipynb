{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at valhalla/longformer-base-4096-finetuned-squadv1 were not used when initializing LongformerForQuestionAnswering: ['longformer.pooler.dense.bias', 'longformer.pooler.dense.weight']\n",
      "- This IS expected if you are initializing LongformerForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from helpers_function import *\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"valhalla/longformer-base-4096-finetuned-squadv1\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"valhalla/longformer-base-4096-finetuned-squadv1\", return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls, company_names, segment = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "questions = ['what is the name of this company?', 'when was this company established?', 'what is the company ISO certification?', 'what is the total number of employees?', 'what is the growth rate of this company?', 'what is the revenue of this company?', 'where is the global HQ location of this company?', 'on what field this company works?', 'what is the vision of this company?', 'what are the past awards that has been awarded to this company?', 'Describe about this company.', 'what is the name of the parent company?', 'what is the company external ICT spend?', 'what is the company R&D spend?', 'what is the company R&D focus?', 'what is the marketing budget of this company?', 'what is the number of patents of this company?']\n",
    "print(len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [29:32, 590.95s/it]\n"
     ]
    }
   ],
   "source": [
    "os.mkdir(f\"D:/Machine Learning/scrapper and extraction/valhalla_answers\")\n",
    "\n",
    "final_answer = []\n",
    "\n",
    "for i, company in tqdm(enumerate(company_names)):\n",
    "    answers = []\n",
    "    for j in range(5):\n",
    "        path = f\"D:/Machine Learning/scrapper and extraction/raw_text/{company}/my_file_{j}.txt\"\n",
    "        text = get_text(path)\n",
    "\n",
    "        if text == \"\":\n",
    "            continue\n",
    "\n",
    "        ans = []\n",
    "\n",
    "        for ques in questions:\n",
    "            text = text\n",
    "            question = ques\n",
    "            encoding = tokenizer(question, text, return_tensors=\"pt\")\n",
    "            input_ids = encoding[\"input_ids\"]\n",
    "\n",
    "            # default is local attention everywhere\n",
    "            # the forward method will automatically set global attention on question tokens\n",
    "            attention_mask = encoding[\"attention_mask\"]\n",
    "\n",
    "            start_scores, end_scores = model(input_ids, attention_mask=attention_mask)\n",
    "            all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
    "\n",
    "            answer_tokens = all_tokens[torch.argmax(start_scores) :torch.argmax(end_scores)+1]\n",
    "            answer = tokenizer.decode(tokenizer.convert_tokens_to_ids(answer_tokens))\n",
    "\n",
    "            ans.append(answer)\n",
    "        \n",
    "        answers.append(ans)\n",
    "\n",
    "    final_answer.append(answers)\n",
    "\n",
    "    # file = f\"D:/Machine Learning/scrapper and extraction/valhalla_answers/{company}.txt\"\n",
    "    # with open(file, \"w\") as f:\n",
    "    #     for k, ques in enumerate(questions):\n",
    "    #         f.write(f'Questions: {ques}\\nAnswer: {[ans[i] for ans in answers]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5 17\n"
     ]
    }
   ],
   "source": [
    "print(len(final_answer), len(final_answer[0]), len(final_answer[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Woebot for Adults', ' After two weeks', '<s>what is the company ISO certification?</s></s>Woebot for Adults is a non-prescription medical device under FDA enforcement discretion; it is not evaluated, cleared or approved by FDA', ' 2023', ' skyrocketing need for mental health care', ' skyrocketing need for mental health care', '<s>', ' mental health tool that answers the skyrocketing need for mental health care, and breaks down the systemic constraints that block equal access to it. Designed by humans, powered by AI, and grounded in science, Woebot easily integrates with health systems to provide evidenced-based behavioral health solutions that get people off a waitlist, and onto a path to feeling better.We didn’t just digitize CBT; we modeled the entire clinical journey to deliver tools and techniques with the insight and empathy inherent in human relationships. Woebot has been shown to establish a lasting working alliance with users akin to the bond formed between humans. It’s a powerful combination of psychology and technology that’s all digital, and all heart.Techfor thehumanexperience97% of users at a major Integrated Delivery Network (IDN) give Woebot high satisfaction ratingsWoebot Health analysis72 million minutes of mental health support delivered, on demand and in the momentWoebot Health analysisWoebot quickly establishes a lasting bond that is non-inferior to the bond created between human therapists & patientsSource77% of conversations take place outside of work hours. Topics range from relationships to overwhelming workloads, self worth issues, money and bills and moreWoebot Health analysisScaling clinician capacity without adding to burnout. Learn how one major integrated delivery network (IDN) supercharged its clinician workforce to improve access to mental health support.Woebot is at the heart of an AI-powered platform that systematically builds interventions for specific intended uses and patient populations. Our interventions can be used independently, as an adjunct to traditional therapy, or be customized and configured based on your organization’s specific needs, equity gaps, partner ecosystem and objectives. But that’s just the start. We’re excited to be exploring key advances in AI/machine learning for potential future iterations of Woebot, including large language models (LLMs), and be in a position to one day take advantage of some of the greatest leaps in technology that the world has seen.Referred by clinicians\"I have recommended the app to some of my clients, and those who use it have much better outcomes with their thoughts, feelings, and mood than those who don’t.\"Clinician\"Woebot reinforces the concepts my clients are learning, and many of them say they like having someone to turn to 24 hours a day who can help them.\"Clinician“As a therapist', '', 'Referred by clinicians', ' It adds another ‘support network’ for people who could benefit from its content', 'Woebot for Adults is a non-prescription medical device under FDA enforcement discretion; it is not evaluated, cleared or approved by FDA. It is not a prescription product. It is not intended to diagnose, monitor, treat or prevent any disease. It may be considered as an adjunct to clinical care, it does not replace clinical care.Meet Woebot, the mental health tool that answers the skyrocketing need for mental health care, and breaks down the systemic constraints that block equal access to it. Designed by humans, powered by AI, and grounded in science, Woebot easily integrates with health systems to provide evidenced-based behavioral health solutions that get people off a waitlist, and onto a path to feeling better.We didn’t just digitize CBT; we modeled the entire clinical journey to deliver tools and techniques with the insight and empathy inherent in human relationships. Woebot has been shown to establish a lasting working alliance with users akin to the bond formed between humans. It’s a powerful combination of psychology and technology that’s all digital, and all heart.Techfor thehumanexperience97% of users at a major Integrated Delivery Network (IDN) give Woebot high satisfaction ratingsWoebot Health analysis72 million minutes of mental health support delivered, on demand and in the momentWoebot Health analysisWoebot quickly establishes a lasting bond that is non-inferior to the bond created between human therapists & patientsSource77% of conversations take place outside of work hours. Topics range from relationships to overwhelming workloads, self worth issues, money and bills and moreWoebot Health analysisScaling clinician capacity without adding to burnout. Learn how one major integrated delivery network (IDN) supercharged its clinician workforce to improve access to mental health support.Woebot is at the heart of an AI-powered platform that systematically builds interventions for specific intended uses and patient populations. Our interventions can be used independently, as an adjunct to traditional therapy, or be customized and configured based on your organization’s specific needs, equity gaps, partner ecosystem and objectives. But that’s just the start. We’re excited to be exploring key advances in AI/machine learning for potential future iterations of Woebot, including large language models (LLMs), and be in a position to one day take advantage of some of the greatest leaps in technology that the world has seen.Referred by clinicians\"I have recommended the app to some of my clients, and those who use it have much better outcomes with their thoughts, feelings, and mood than those who don’t.\"Clinician', 'support network', '<s>', '<s>', ' 2023', ' 2023']\n"
     ]
    }
   ],
   "source": [
    "print(final_answer[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, company in enumerate(company_names):\n",
    "    file = f\"D:/Machine Learning/scrapper and extraction/valhalla_answers/{company}.txt\"\n",
    "    with open(file, \"w\") as f:\n",
    "        for k, ques in enumerate(questions):\n",
    "            f.write(f'Questions: {ques}\\nAnswer: {[ans[k] for ans in final_answer[i]]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, ques in enumerate(questions):\n",
    "#     print(f'Questions: {ques}\\nAnswer: {[ans[i] for ans in answers]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
