August 2023By: Joe Gallagher, Chief Product Officer and Sharanya Srinivasan, Senior AI Product ManagerWith recent advances in AI, it’s more relevant than ever to ask ourselves what it means to responsibly and effectively use AI, especially Large Language Models (LLMs), in a healthcare setting. Deploying AI to vulnerable populations comes with the potential to inadvertently cause harm. To responsibly deploy any form of AI in our products, we must deeply and intentionally consider the impact that the technology has on users. We’ve outlined below how we think about the management and mitigation of the risks that accompany the use of AI in the mental healthcare field.We recently announced the launch of our first clinical trial exploring LLM technology. The goal of this study is to help us understand how LLMs can be applied to accelerate the delivery of safe, engaging, and potent digital solutions for mental health. As these technologies mature, we expect to better understand what constitutes safe and effective development practices, alongside regulatory guidance. It is also important that companies in this space proactively adopt and share effective practices.Given the broad capabilities of LLMs, we anticipate a spectrum of possible use cases within our products, each requiring due consideration to ensure clinical appropriateness, safety and augmentation to the overall experience. We broadly categorize these into (a) using LLMs to interpret user input and route to content that has been written by a human—essentially using the LLMs only for understanding; and (b) using LLMs to generate responses that will be shown directly to users.While generating responses is a use case that requires additional scoping and safety considerations, we believe that using LLMs for understanding intent combined with human-composed responses provides for improved conversational quality. We currently are learning more about the value and risks of response generation, and we therefore only use generative capabilities in IRB-regulated study settings.All of this is to say that using LLMs will augment our ability to understand natural language from users and better enable us to meet them where they are. As we begin to explore the usage of LLMs in our product and think about how to apply those learnings in future versions of Woebot, we continue to hold ourselves to high standards of safety, rigor and transparency. The following outlines our core principles around responsibly deploying AI, including LLM-based technology, to our users.We are excited and optimistic about the potential of LLMs and are increasingly confident in our ability to build the safest approach to applying AI in healthcare. We will accomplish this by doing what we do best – taking emerging technology and applying rigorous and continuous user research, engineering, clinical and translational science oversight to create more precise, personalized and potent products.Woebot Health Platform is the foundational development platform where components are used for multiple types of products in different stages of development and enforced under different regulatory guidelines.Woebot does not provide crisis counseling and is not a suicide prevention or crisis intervention service. Concerning language and escalation data provided to clinical program or clinical study customers is not reviewed or assessed internally at Woebot Health in real-time for intervention and such data is not used for managing potential crises or any acute or non-acute patient safety issue. Discomfort may be experienced when answering sensitive questions. Temporary upset may occur as a result of discontinued access”Note, August 2023: Our research into large language models (LLMs) is exploratory. In our commercially or publicly available products, we do not use LLMs to generate responses to users; all text is developed by our conversational writers, and always with clinical oversight.© 2023 Woebot Health© 2023 Woebot HealthSign up for Meeting of the Minds video & podcastsSign up for Meeting of the Minds video & podcasts© 2023 Woebot Health